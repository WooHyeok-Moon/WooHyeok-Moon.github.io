<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Axiomize</title>
    <link>https://WooHyeok-Moon.github.io/posts/</link>
    <description>Recent content in Posts on Axiomize</description>
    <image>
      <title>Axiomize</title>
      <url>https://WooHyeok-Moon.github.io/papermod-cover.png</url>
      <link>https://WooHyeok-Moon.github.io/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>kr</language>
    <lastBuildDate>Tue, 06 Feb 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://WooHyeok-Moon.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>확률의 정의</title>
      <link>https://WooHyeok-Moon.github.io/posts/sm2/</link>
      <pubDate>Tue, 06 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>https://WooHyeok-Moon.github.io/posts/sm2/</guid>
      <description>러시아의 수학자 콜모고로프(Andrei Kolmogorov, 1903~1987)는 확률을 공리적으로 정의하고자 하였으며 다음과 같은 공리가 확률을 정의하는 필요충분조건이 됨을 보였다.
확률의 공리 (1) 임의의 사건 $A$에 대하여 $P(A) \ge 0$이다.
(2) $P(S) = 1$이다.
(3) 표본공간 $S$에 정의된 사건열 $A_1, A_2, \cdots$ 가 있다고 하자. 이제 모든 $i \ne j$에 대하여 $A_i \cap A_j = \varnothing$ 이면 $P(\displaystyle\bigcup_{i=1}^{\infty}A_i = \displaystyle\sum_{i=1}^{\infty}P(A_i)$이다.
정리 1.1 두 개의 사건 $A$와 $B$에 대하여 다음과 같은 성질들이 성립한다.
$P(A^c) = 1 - P(A)$ $P(\varnothing) = 0$ $A \subset B$이면 $P(A) \le P(B)$이다.</description>
    </item>
    
    <item>
      <title>표본공간과 사건</title>
      <link>https://WooHyeok-Moon.github.io/posts/sm1/</link>
      <pubDate>Mon, 05 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>https://WooHyeok-Moon.github.io/posts/sm1/</guid>
      <description>1. 확률이론 1.1 표본공간과 사건 키워드 실험: 어떤 현상의 관찰결과를 얻기 위한 과정 표본공간($S$): 모든 관찰 가능한 결과의 집합 사건: 표본공간의 부분집합 정의 1.1 사건 $A$와 $B$가 표본공간 $S$상에 정의되었다고 하자.
사건 $A$와 $B$가 동시에 속하는 사건을 $A$와 $B$의 공통부분이라고 하고 $A \cap B$라고 표기한다. 사건 $A$ 또는 $B$에 속하는 사건을 $A$와 $B$의 합이라고 하고 $A \cup B$로 표기한다. 예 1.1 동전을 3회 던지는 실험에서 앞면을 $H$, 뒷면을 $T$로 표시하면 표본공간은 $$ S = {\ HHH,\ HHT,\ HTH,\ THH,\ HTT,\ THT,\ TTH,\ TTT\ } $$ 이고, &amp;lsquo;2회 앞면이 나오는 사건&amp;rsquo;은 $$ A = {\ HHT,\ HTH,\ THH\ } $$ 이다.</description>
    </item>
    
    <item>
      <title>AI대학원 면접 준비</title>
      <link>https://WooHyeok-Moon.github.io/posts/ai_0/</link>
      <pubDate>Tue, 11 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://WooHyeok-Moon.github.io/posts/ai_0/</guid>
      <description>Statistics 1. Central Limit Theorem 표본의 개수 $n$이 충분히 클 때 표본 분포가 정규분포 $N(\mu, \sigma^2)$에 근사하는 것
$E(\bar{x}) \rightarrow \mu$
Deep $\cdot$ Machine Learning 1. L1, L2 Regulerization 과제: 과적합을 감소시켜야 한다.
해결 방법: 규제(Regulerization)
과적합을 감소시키기 위해서 규제라는 개념을 도입하게 되는데, 이렇게 규제가 적용된 regression에는 Ridge와 Lasso가 있다.
Ridge는 L2, Lasso는 L1 norm이 규제로써 작동되는 regression으로, L1 norm은 manhattan distance이고, L2 norm은 euclidean distance의 개념이다.
L1 norm은 특정 feature을 없앨 수 있어 feature selection에 유리하다.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://WooHyeok-Moon.github.io/posts/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://WooHyeok-Moon.github.io/posts/test/</guid>
      <description>test kr</description>
    </item>
    
  </channel>
</rss>
