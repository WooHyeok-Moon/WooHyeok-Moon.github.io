<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Axiomize</title>
    <link>https://WooHyeok-Moon.github.io/posts/</link>
    <description>Recent content in Posts on Axiomize</description>
    <image>
      <title>Axiomize</title>
      <url>https://WooHyeok-Moon.github.io/papermod-cover.png</url>
      <link>https://WooHyeok-Moon.github.io/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>kr</language>
    <lastBuildDate>Tue, 26 Mar 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://WooHyeok-Moon.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>랜덤 프로세스 내용</title>
      <link>https://WooHyeok-Moon.github.io/posts/rp0/</link>
      <pubDate>Tue, 26 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>https://WooHyeok-Moon.github.io/posts/rp0/</guid>
      <description>Lecture 1 Relative Frequency Interpretation Set Theory Applying Set Theory to Probability Probability Axioms Lecture 2 Conditional Probability Law of Total Probability Bayes Theorem Statistical Independence Bernoulli Trials Reliability Problems Lecture 3 Bernulli trials, Binomial, and Poisson law De Moivre-Laplace Theorem Probability Review Summary Lecture 4 Definitions of Random Variable Examples of Random Variable Cumulative Distribution Function Probability Density Function Probability Mass Function Continuous-Type Random Variables Discrete-Type Random Variables Lecture 5 Two Random Variables Random Vector Complex Random Variable Conditional Distributions/Densities Independence of Random Variables Functions of Random Variables Functions of Random Vectors Lecture 6 Expected Value of a Random Variable Moments of Random Variable Uncorrelated and Orthogonal Random Variables Markov Inequality Chebyshev (Tschebysheff) Inequality Moment Generation Function (MGF) and Characteristic Fuction Characteristic Function for a Random Vector Characteristic Function Example Lecture 7 Conditional Expectation Application of Expectation-Estimation Communication Theory Example Linear minimum mean squared error(LMMSE) estimator LMMSE Estimator from a Random Vector Lecture 8 Expected Value Vector and Matrix Correlation and Covariance Matrix Cross-correlation and Cross-covariance Matrix Univariate Normal Random Variable Bivariate Normal Random Variables Multivariate Normal Random Variables Lecture 9 (pending) Lecture 10 (pending) </description>
    </item>
    
    <item>
      <title>기초통계</title>
      <link>https://WooHyeok-Moon.github.io/posts/si2/</link>
      <pubDate>Fri, 15 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>https://WooHyeok-Moon.github.io/posts/si2/</guid>
      <description>데이터 요약(summarization)은 데이터 volume을 줄이는 효과 뿐 아니라, 복잡한 데이터로부터 패턴, 추세, 이상징후와 같은 insight를 추출해낼 수 있다.
1) 대표값, 중심 측도(Measure of Location) 대표값을 통해 중요한 insight를 얻을 수 있다. 이러한 대표값들은 데이터의 변화, 영향 및 분석 결과를 평가하는 기준을 제공한다.
1.1) 평균(Arithmetic Mean) 1.1.1) 정의 및 계산 값들을 모두 더한 뒤 sample 수로 나누어준다.
$$\bar{X} = \frac{\sum_{i=1}^{n} X_i}{n}$$
1.1.2) 그룹화된 데이터 $k$개의 그룹으로 나뉜 데이터의 전체 평균은, 각 그룹의 평균에 그룹별 sample size만큼 가중치를 주어 계산한다.</description>
    </item>
    
    <item>
      <title>환경 데이터 종류</title>
      <link>https://WooHyeok-Moon.github.io/posts/si1/</link>
      <pubDate>Thu, 14 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>https://WooHyeok-Moon.github.io/posts/si1/</guid>
      <description>Basics of Environmental Data 1) 환경 데이터 특징 1.1) 시계열 데이터 (Time-series data) continous한 시간 간격에 따른 데이터. 시간, 일 또는 월 별 데이터와 같이 규칙적일 수도 있고, interval 자체가 불규칙적일 수도 있다.
예시:
계절, 연 단위의 강우량 변화 강, 호수, 댐 등의 수위 호수나 시냇물의 유량 pH, 혼탁도, 오염도 등과 같은 수질 시계열 데이터 특성:
시간 종속성(Temporal dependency): 일반적인 데이터와 다르게 시계열 데이터는 고려해야 할 X(독립 변수) 시간 경과에 따른 특징이 존재하며, 이를 통해 유용한 정보를 얻을 수 있다.</description>
    </item>
    
    <item>
      <title>마크다운(markdown) KaTex 공식 정렬 시 번호 제거</title>
      <link>https://WooHyeok-Moon.github.io/posts/md1/</link>
      <pubDate>Tue, 06 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>https://WooHyeok-Moon.github.io/posts/md1/</guid>
      <description>마크다운에서 아래와 같이 식을 정렬하고 싶을 때가 있다.
$$ f(x) = ax_1 + bx_2 = cx_3 + dx_4 = ex_5 + fx_6\\\ \downarrow\\\ \begin{align} f(x) &amp;amp;= ax_1 + bx_2\\\ &amp;amp;= cx_3 + dx_4\\\ &amp;amp;= ex_5 + fx_6\\\ \end{align} $$ $$ f(x) = ax_1 + bx_2 = cx_3 + dx_4 = ex_5 + fx_6\\ \downarrow\\ \begin{align} f(x) &amp;amp;= ax_1 + bx_2\\ &amp;amp;= cx_3 + dx_4\\ &amp;amp;= ex_5 + fx_6\\ \end{align} $$</description>
    </item>
    
    <item>
      <title>확률의 정의</title>
      <link>https://WooHyeok-Moon.github.io/posts/sm2/</link>
      <pubDate>Tue, 06 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>https://WooHyeok-Moon.github.io/posts/sm2/</guid>
      <description>러시아의 수학자 콜모고로프(Andrei Kolmogorov, 1903~1987)는 확률을 공리적으로 정의하고자 하였으며 다음과 같은 공리가 확률을 정의하는 필요충분조건이 됨을 보였다.
확률의 공리 (1) 임의의 사건 $A$에 대하여 $P(A) \ge 0$이다.
(2) $P(S) = 1$이다.
(3) 표본공간 $S$에 정의된 사건열 $A_1, A_2, \cdots$ 가 있다고 하자. 이제 모든 $i \ne j$에 대하여 $A_i \cap A_j = \varnothing$ 이면 $P(\displaystyle\bigcup_{i=1}^{\infty}A_i = \displaystyle\sum_{i=1}^{\infty}P(A_i)$이다.
정리 1.1 두 개의 사건 $A$와 $B$에 대하여 다음과 같은 성질들이 성립한다.
$P(A^c) = 1 - P(A)$ $P(\varnothing) = 0$ $A \subset B$이면 $P(A) \le P(B)$이다.</description>
    </item>
    
    <item>
      <title>표본공간과 사건</title>
      <link>https://WooHyeok-Moon.github.io/posts/sm1/</link>
      <pubDate>Mon, 05 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>https://WooHyeok-Moon.github.io/posts/sm1/</guid>
      <description>1. 확률이론 1.1 표본공간과 사건 키워드 실험: 어떤 현상의 관찰결과를 얻기 위한 과정 표본공간($S$): 모든 관찰 가능한 결과의 집합 사건: 표본공간의 부분집합 정의 1.1 사건 $A$와 $B$가 표본공간 $S$상에 정의되었다고 하자.
사건 $A$와 $B$가 동시에 속하는 사건을 $A$와 $B$의 공통부분이라고 하고 $A \cap B$라고 표기한다. 사건 $A$ 또는 $B$에 속하는 사건을 $A$와 $B$의 합이라고 하고 $A \cup B$로 표기한다. 예 1.1 동전을 3회 던지는 실험에서 앞면을 $H$, 뒷면을 $T$로 표시하면 표본공간은 $$ S = {\ HHH,\ HHT,\ HTH,\ THH,\ HTT,\ THT,\ TTH,\ TTT\ } $$ 이고, &amp;lsquo;2회 앞면이 나오는 사건&amp;rsquo;은 $$ A = {\ HHT,\ HTH,\ THH\ } $$ 이다.</description>
    </item>
    
    <item>
      <title>AI대학원 면접 준비</title>
      <link>https://WooHyeok-Moon.github.io/posts/ai_0/</link>
      <pubDate>Tue, 11 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://WooHyeok-Moon.github.io/posts/ai_0/</guid>
      <description>Statistics 1. Central Limit Theorem 표본의 개수 $n$이 충분히 클 때 표본 분포가 정규분포 $N(\mu, \sigma^2)$에 근사하는 것
$E(\bar{x}) \rightarrow \mu$
Deep $\cdot$ Machine Learning 1. L1, L2 Regulerization 과제: 과적합을 감소시켜야 한다.
해결 방법: 규제(Regulerization)
과적합을 감소시키기 위해서 규제라는 개념을 도입하게 되는데, 이렇게 규제가 적용된 regression에는 Ridge와 Lasso가 있다.
Ridge는 L2, Lasso는 L1 norm이 규제로써 작동되는 regression으로, L1 norm은 manhattan distance이고, L2 norm은 euclidean distance의 개념이다.
L1 norm은 특정 feature을 없앨 수 있어 feature selection에 유리하다.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://WooHyeok-Moon.github.io/posts/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://WooHyeok-Moon.github.io/posts/test/</guid>
      <description>test kr</description>
    </item>
    
  </channel>
</rss>
