{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e072cbcd-62c0-4fff-80ec-e034c69c03a8",
   "metadata": {},
   "source": [
    "---\n",
    "author: \"Woohyeok Moon\"\n",
    "date: 2023-07-11\n",
    "title: AI대학원 면접 준비\n",
    "categories: Artificial Intelligence\n",
    "tags: [Machine Learning, Deep Learning]\n",
    "showtoc: false\n",
    "weight: 10\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b38c2-b001-44eb-b5ae-6ecb1e5065d1",
   "metadata": {},
   "source": [
    "## 1. L1, L2 Regulerization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a7adc-b5d7-4825-a5ab-9332c9e355bc",
   "metadata": {},
   "source": [
    "- 과제: 과적합을 감소시켜야 한다.\n",
    "- 해결 방법: 규제(Regulerization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8335696-18ad-4127-84b4-0532e78a825d",
   "metadata": {},
   "source": [
    "- 과적합을 감소시키기 위해서 규제라는 개념을 도입하게 되는데, 이렇게 규제가 적용된 regression에는 Ridge와 Lasso가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3baccd1-b6db-4959-b341-bb356ba34e41",
   "metadata": {},
   "source": [
    "- Ridge는 L2, Lasso는 L1 norm이 규제로써 작동되는 regression으로, L1 norm은 manhattan distance이고, L2 norm은 euclidean distance의 개념이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce0a7e-2f89-4f9c-a856-c8f471ae82ec",
   "metadata": {},
   "source": [
    "- L1 norm은 특정 feature을 없앨 수 있어 feature selection에 유리하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a678ad-7d07-445f-8746-425005948294",
   "metadata": {
    "tags": []
   },
   "source": [
    "- L2 norm은 제곱 연산이 들어있어 이상치에 민감하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37486152-8c66-48d7-aaa7-c301070d7b17",
   "metadata": {},
   "source": [
    "- L1 norm은 절댓값이 취해져 있어 0에서 미분불가능하다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f5f11b-bc36-4c51-83f7-ec7328b25144",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a9d0f-6369-4079-8a44-f1bde74c1e7e",
   "metadata": {},
   "source": [
    "- 손실함수의 비용이 최소가 되는 지점을 찾을 때까지 기울기가 낮은 쪽으로 계속 이동시키는 과정을 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7067177-ce16-4e92-bff6-b6cb2e9c8cde",
   "metadata": {},
   "source": [
    "- 이때 x축은 weight, y축은 cost이다. cost가 최소가 되도록 weight값을 갱신하는 과정을 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a677670-1cf4-42ea-8ba3-4c0eee6eab82",
   "metadata": {},
   "source": [
    "- 초기 형태인 Batch Gradient Descent는 한 번에 모든 데이터를 업데이트하기 때문에 대용량 데이터를 처리하기에 적합하지 않다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06518e-1f31-4ad5-ba3d-455adf8d34d6",
   "metadata": {},
   "source": [
    "## Sthochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e935ea2-6041-4641-8046-5ea66c40aca6",
   "metadata": {},
   "source": [
    "- 그리하여 데이터셋을 batch 단위로 쪼개 학습하는 방법을 적용하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e6c298-03fe-4165-8cb7-dd6e35d811e6",
   "metadata": {},
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e055c4-7750-4c2a-ad47-993b00c7e286",
   "metadata": {},
   "source": [
    "- internal covariate shift를 줄이기 위한 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025147b9-d8ab-49ef-b6be-a4c23a280f3b",
   "metadata": {},
   "source": [
    "- covariate shift란 train set의 분포와 test set의 분포가 달라 제대로 예측하지 못하는 현상을 말함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1216772b-ead9-47d9-b30a-589b09acd608",
   "metadata": {},
   "source": [
    "- internal covariate shift는 이러한 현상이 neural network 내부에서 일어나는 것을 말하는데, hidden layer에 입력으로 들어오는 데이터의 분포가 달라지는 것을 의미하며, layer가 깊을수록 심화될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d27faf-abbf-49d1-b032-d4a29970a906",
   "metadata": {},
   "source": [
    "- 또한 이는 mini batch 기법에서는 batch마다 분포가 달라져 특히 성능에 critical한 문제가 될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d35b6-d7b7-42d8-bb9d-f8b462dbd2c2",
   "metadata": {},
   "source": [
    "- 이 분포를 단순히 whitening하게 되면 편향이 사라지게 되어 유의미한 정보가 유실될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7853d146-d850-4c7c-8593-74b877459669",
   "metadata": {},
   "source": [
    "- batch마다 평균과 분산을 계산하여 표준화하되 scale factor($\\gamma$)와 shift factor($\\beta$)를 적용시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b3c8d8-2db6-4c50-9a18-44b819963fdb",
   "metadata": {},
   "source": [
    "- 학습 시 batch normalization은 activation function으로 들어가기 전에 수행되는데, scale factor와 shift factor가 들어옴으로써 relu를 사용할 때 음수에 해당하는 부분이 모두 0으로 사라져버리는 것을 방지할 수 있고, sigmoid activation function을 사용할 때 비선형성이 사라지는 현상 또한 방지할 수 있고, normalization하기 전인 원래 형태에 대해서도 학습을 진행할 수 있어 backpropagation 또한 적용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fa7faf-fc1f-400e-aedf-b221ef97567b",
   "metadata": {
    "tags": []
   },
   "source": [
    "- 추론 시 batch normalization은 테스트 데이터 하나에 대해 답을 내야 하므로 평균과 분산을 낼 수 없으므로 training 시 mini-batch들의 평균과 분산을 대신 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ff955-4db8-4bb8-9d3d-f9a9da8c6873",
   "metadata": {},
   "source": [
    "## CNN(Convolution Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c11ee-49ee-4124-9e3a-027ce90c07a1",
   "metadata": {},
   "source": [
    "- 기존의 DNN은 1차원 형태의 데이터를 사용하므로 2차원 형태의 이미지가 입력값으로 들어왔을 때에는 1차원으로 Flatten시켜줘야 한다. 이 과정에서 정보 손실이 일어난다. 또한 추상화 과정 없이 바로 연산을 진행하는데, 이로 인해 효율성이 저하된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6f484-524d-478d-9e29-ff8d84499a1f",
   "metadata": {},
   "source": [
    "- CNN은 이미지를 이미지 그대로 받아 공간적/지역적 정보를 유지할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb920c5-9c3a-4593-99bf-2d2d5cf8a804",
   "metadata": {},
   "source": [
    "- 이미지는 이미지 전체보다는 특징적인 부분과 그 주변 픽셀들의 연관성에 집중해야 한다. CNN은 이를 위해 Convolution 연산을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6778734-4353-46d4-ad57-58866478853b",
   "metadata": {},
   "source": [
    "- 하나의 Convolution layer에는 Convolution과 Activation이 포함되어 있다. Activation Function으로는 RELU를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168daa07-775e-4e8a-9b44-ec1948a597ac",
   "metadata": {},
   "source": [
    "- 이후 생성된 여러 개의 결과값에 Max Pooling을 적용하여 크기를 줄여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1054bd15-db33-4edf-bdaa-d3f61c3bef76",
   "metadata": {},
   "source": [
    "- 다시 Convolution, Activation, Pooling을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78daecd-9cac-4e66-9753-85f81141a375",
   "metadata": {},
   "source": [
    "- 나온 Feature data들을 Flatten하여 1차원 형태의 데이터로 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d18fe-9f80-46f0-9cb7-fb46847d9385",
   "metadata": {},
   "source": [
    "- FC(Fully connected) layer를 통과시켜 Softmax를 적용해주면 최종 output이 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1328a9-3f15-4831-9eaa-9f55a0a9787e",
   "metadata": {},
   "source": [
    "## Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715bf54-e008-479b-8797-4386879e2b77",
   "metadata": {
    "tags": []
   },
   "source": [
    "- 활성화 함수는 선형 분류기를 비선형 분류기로 만들어주는 역할을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c5220a-5cba-493b-a4b2-334e2476966a",
   "metadata": {},
   "source": [
    "- 선형 함수를 사용하면 층을 깊게 쌓는 의미가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ab0c19-ea98-40a7-a477-657d5c32846b",
   "metadata": {
    "tags": []
   },
   "source": [
    "- 활성화 함수 없이 feedforward를 진행하게 된다면 아래와 같이 진행된다.\n",
    "$$ f(x) = w*x\\\\\n",
    "f(f(x)) = w*w*x = w^2x\\\\\n",
    "f(f(f(x))) = w*w*w*x = w^3x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b7f9d2-a27f-4f37-a170-b9231c16f80f",
   "metadata": {},
   "source": [
    "- 이는 $y = ax$인 선형 함수에서 $a = w^3$인 선형 함수가 되었을 뿐이며 이는 weight가 $w^3$인 한 개 층으로도 네트워크를 구성할 수 있음을 의미한다. -> Deep Network의 의미가 없다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
